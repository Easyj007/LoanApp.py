# -*- coding: utf-8 -*-
"""My_Project_AXIA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13g_szU511kHRDkMhW1BY6ZYIW3EpNbc2

## PROBLEM STATEMENT
Develop a robust machine learning pipeline to predict loan default risk, that will  enable better credit decisions and minimizing financial losses.

### SOLUTION
Utilize customer behavioral and financial data to build a predictive model, enhancing accuracy and efficiency in risk assessment.

#### KEY TECHNOLOGIES
Python: Data cleaning, EDA, Modeling

Power BI: Dashboarding & Insights

Libraries: Pandas, Scikit-learn, XGBoost, Matplotlib,Numpy,Seaborn
"""

#Loading libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

#Load datasets
df1 = pd.read_csv('https://raw.githubusercontent.com/Oyeniran20/axia_cohort_8/refs/heads/main/trainperf.csv')
df2 = pd.read_csv('https://raw.githubusercontent.com/Oyeniran20/axia_cohort_8/refs/heads/main/traindemographics.csv')
df3 = pd.read_csv('https://raw.githubusercontent.com/Oyeniran20/axia_cohort_8/refs/heads/main/trainprevloans.csv')

"""### DATA UNDERSTANDING

Our analysis relies on a comprehensive dataset, simulating real-world loan application scenarios to capture critical indicators of default risk.

#### ASSUMED DATA COLUMNS

*Dataset_1(Financial) - Monthly Income, Debt-to-Income Ratio, Credit Score, Loan Amount, Loan Purpose

*DataSet_2(Demographics) - Age, Gender, Marital Status, Education, Employment Status

*Dataset_3(Behavioural) - Number of Credit Cards, Past Due Days, Missed Payments (last 6 months)

TARGET COLUMN:
Loan Default (0: No, 1: Yes)
"""

df1.head()

df1.info()

#Renaming the columns
df1.columns = ['customer_id','system_loan_id', 'loan_number', 'approved_date', 'creation_date', 'loan_amount', 'total_due', 'term_days', 'referred_by', 'good_bad_flag']

df1.shape

df1.columns

#Checking for duplicates
df1.duplicated().sum()

#checking for missing values
df1.isna().sum().sort_values(ascending=False)

#checking missing values by percentage in each column
(df1.isna().sum().sort_values(ascending=False)/len(df1))*100

#dropping the column with more than 60 percent missing values
df1=df1.drop(columns=['referred_by'])

df1.describe().T

"""## Dataset 2"""

df2.head()

#rename some of the columns
df2=df2.rename(columns={'customerid': 'customer_id', 'birthdate' : 'birth_date'})

df2.shape

df2.columns

df2.info()

#checking for duplicates
df2.duplicated().sum()

#drop the duplicates
df2.drop_duplicates(inplace=True)

#checking for missing values by percentage
(df2.isna().sum().sort_values(ascending=False)/len(df2))*100

#dropping columns with more than 80 percent missing values
df2=df2.drop(columns=['bank_branch_clients','level_of_education_clients'])

#fill the missing values of the column that has less than 20 percent missing values

mode_value = df2['employment_status_clients'].mode()[0]  #finds the mode value of the column

df2['employment_status_clients'] = df2['employment_status_clients'].fillna(mode_value) #fill in the missing values with mode value

"""### Fill in the missing values with mode because it is a categorical column"""

#df2.isna().sum().sort_values(ascending=False)

#df2.describe().T

"""### Dataset three"""

df3.head()

#renaming the columns
df3.columns = ['customer_id','system_loan_id', 'loan_number', 'approved_date', 'creation_date', 'loan_amount', 'total_due', 'term_days','closed_date', 'referred_by', 'first_due_date','first_repaid_date']

df3.shape

df3.columns

df3.info()

df3.duplicated().sum()

#checking missing values
df3.isna().sum().sort_values(ascending=False)

#drop column with more than 80 percent missing values
df3=df3.drop(columns=['referred_by'])

df3.describe().T

#merge data 1 and 2 by left
temp_df = pd.merge(df1, df2, how='left')

temp_df.head()

temp_df.shape

temp_df.info(10)

temp_df.isna().sum()

#checking missing values by percentage in each column
(temp_df.isna().sum().sort_values(ascending=False)/len(temp_df))*100

temp_df.duplicated().sum()



#merge data 1 and 2 by inner
temp_df2 = pd.merge(df1, df2, how='inner')
temp_df2.head()

temp_df2.shape

temp_df2.info(10)

temp_df2.isna().sum()

#checking missing values by percentage in each column
(temp_df2.isna().sum().sort_values(ascending=False)/len(temp_df2))*100

temp_df2.duplicated().sum()

"""#### merging dataset 1 and 2 by how= left has alot of missing values(rows) than how=inner, hence i will make use of how=inner while merging so as to increase the integrity of the dataset"""

#fill the missing values of the column that has less than 20 percent missing values

mode_value = temp_df2['employment_status_clients'].mode()[0]  #finds the mode value of the column

temp_df2['employment_status_clients'] = temp_df2['employment_status_clients'].fillna(mode_value) #fill in the missing values with mode value

temp_df2.isna().sum().sort_values()

"""#### Finding the base model without transforming the dataset using the decision tree model for classification problem."""

#To visualize the target column
df_base = temp_df2
df_base.good_bad_flag.value_counts().plot(kind='bar')

"""##### Data preparation"""

x = df_base.drop(['good_bad_flag','customer_id','system_loan_id','approved_date','creation_date'], axis=1)
y = df_base['good_bad_flag']

#split into train and test
from sklearn.model_selection import train_test_split
x_base_train,x_base_test,y_train,y_test = train_test_split(x,y, test_size=0.2, random_state=42, stratify=y)

#covert target column to numbers using label encoder

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

# Fit encoder on training labels, transform both train and test labels
y_base_train = label_encoder.fit_transform(y_train)
y_base_test = label_encoder.transform(y_test)

"""##### Data pre-processing"""

# separate into cat_cols and num_cols
num_cols_base = x.select_dtypes(include=np.number).columns.tolist()
cat_cols_base = x.select_dtypes(include='object').columns.tolist()

"""## CREATING A PIPELINE"""

#importing libraries

from sklearn.preprocessing import StandardScaler,OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC

"""### WHAT IS A PIPELINE?

A pipeline
"""

#To create a pipeline for the data preprocessing

num_pipeline = Pipeline(steps=[
    ('scalar', StandardScaler())
    ])
cat_pipeline = Pipeline(steps=[
    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))
    ])

#Applying the preprocessing

preprocessor = ColumnTransformer(transformers= [
    ('num', num_pipeline, num_cols_base),
    ('cat', cat_pipeline, cat_cols_base)
])

"""##### ColumnTransformer
Applying a ColumnTransformer within your pipeline to apply transformers selectively to the appropriate columns.
This ensures a clean, maintainable, and correct preprocessing flow inside the pipeline.
"""

#using several methods
#import libraries

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

#import metrics
from sklearn.metrics import (accuracy_score,confusion_matrix,ConfusionMatrixDisplay,
                                classification_report,precision_score,
                                recall_score,f1_score)

#Define the models

models = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Boost': GradientBoostingClassifier(random_state=42),
    'SV Machine': SVC(random_state=42)
}

# Commented out IPython magic to ensure Python compatibility.
#Fit and evaluate the models

results = {}

fig, axes = plt.subplots(2,3, figsize=(15, 8))


for (name, model), ax in zip (models.items(), axes. flatten()):
    pipeline= Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])
    #model training
#     %time
    pipeline.fit(x_base_train, y_base_train)
     #prediction
    train_pred_base= pipeline.predict(x_base_train)
    test_pred_base = pipeline.predict(x_base_test)
#train_base_pred,test_base_pred

#Evaluation

    train_score_base = accuracy_score(y_base_train, train_pred_base)
    test_score_base = accuracy_score(y_base_test, test_pred_base)
    precision = precision_score(y_base_test, test_pred_base)
    recall = recall_score(y_base_test, test_pred_base)
    f1 = f1_score(y_base_test, test_pred_base)
    #Confusion_Matrix= confusion_matrix(y_base_test, test_pred_base)

    results[name] = {
    "Train Accuracy": train_score_base,
    "Test Accuracy": test_score_base,
    "Precision Score": precision,
    "Recall Score": recall,
    "F1 Score": f1,
    #"Confusion Matrix":  Confusion_Matrix

    }
    cm= confusion_matrix(test_pred_base, y_base_test)
    disp = ConfusionMatrixDisplay(cm, display_labels=['No','Yes'])
    #fig, ax = plt.subplots(figsize=(8, 6))
    disp.plot(ax=ax, cmap = 'Blues')
    ax.set_title(name)

plt.tight_layout()
plt.show()

pd.DataFrame(results)

"""#### Balancing the target column"""

x = df_base.drop(['good_bad_flag','customer_id','system_loan_id','approved_date','creation_date'], axis=1)
y = df_base['good_bad_flag']

#split into train and test
from sklearn.model_selection import train_test_split
x_base_train,x_base_test,y_train,y_test = train_test_split(x,y, test_size=0.2, random_state=42, stratify=y)

#we have to covert target column to numbers by using label encoder
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

# Here we fit the encoder on the training  and then transform
y_base_train = label_encoder.fit_transform(y_train)
y_base_test = label_encoder.transform(y_test)

# we separate into cat_cols and num_cols
num_cols_base = x.select_dtypes(include=np.number).columns.tolist()
cat_cols_base = x.select_dtypes(include='object').columns.tolist()

#importing libraries
from sklearn.preprocessing import StandardScaler,OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

#To create a pipeline for the data preprocessing
num_pipeline = Pipeline(steps=[
    ('scalar', StandardScaler())
    ])
cat_pipeline = Pipeline(steps=[
    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))
    ])

#Applying the preprocessing
preprocessor = ColumnTransformer(transformers= [
    ('num', num_pipeline, num_cols_base),
    ('cat', cat_pipeline, cat_cols_base)
    ])

#we pass the preprocessor to the training data.
x_base_train_processed = preprocessor.fit_transform(x_base_train)
x_base_test_processed = preprocessor.transform(x_base_test)

# we can now apply SMOTE to the processed training data.

from imblearn.over_sampling import SMOTE

smote_base = SMOTE(random_state=42)

x_base_train_resampled2, y_base_train_resampled2 = smote_base.fit_resample(x_base_train_processed, y_base_train)

#We visualize the balanced target column

import seaborn as sns

sns.countplot(x=y_base_train_resampled2)

#using several methods
#import libraries

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC

#import metrics
from sklearn.metrics import (accuracy_score,confusion_matrix,ConfusionMatrixDisplay,
                            classification_report,precision_score,
                            recall_score,f1_score)

#we define the models
models = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Boost': GradientBoostingClassifier(random_state=42),
    'SV Machine': SVC(random_state=42)
}

# Commented out IPython magic to ensure Python compatibility.
#Fit and evaluate the models
results2 = {}

fig, axes = plt.subplots(2,3, figsize=(15, 8))


for (name, model), ax in zip (models.items(), axes. flatten()):

    pipeline= Pipeline(steps=[
        #('preprocessor', preprocessor),
        ('model', model)
    ])
    #model training
#     %time
    pipeline.fit(x_base_train_resampled2, y_base_train_resampled2)
     #prediction
    train_pred_base_resampled = pipeline.predict(x_base_train_resampled2)
    test_pred_base_resampled = pipeline.predict(x_base_test_processed)
#train_base_pred,test_base_pred

#Evaluation

    train_score_base = accuracy_score(y_base_train_resampled2, train_pred_base_resampled)
    test_score_base = accuracy_score(y_base_test, test_pred_base_resampled)
    precision = precision_score(y_base_test, test_pred_base_resampled)
    recall = recall_score(y_base_test, test_pred_base_resampled)
    f1 = f1_score(y_base_test, test_pred_base_resampled)

    results2[name] = {
    "Train Accuracy": train_score_base,
    "Test Accuracy": test_score_base,
    "Precision Score": precision,
    "Recall Score": recall,
    "F1 Score": f1
    }

    cm= confusion_matrix(test_pred_base, y_base_test)
    disp = ConfusionMatrixDisplay(cm, display_labels=['No','Yes'])
    disp.plot(ax=ax, cmap = 'Blues')
    ax.set_title(name)

plt.tight_layout()
plt.show()


#print matrics
#print('\nclassification Matrics')
#matrics_df=pd.DataFrame(results2)
#print(matrics_df.round(2))

pd.DataFrame(results2)

#print matrics

print('\nclassification Matrics')
metrics_df=pd.DataFrame(results2)
print(metrics_df.round(2))

"""#### MODELS PERFORMANCE

For the unbalanced data:
Random Forest has the highest test accuracy (0.783) and highest F1 score (0.878).

All the models except Decision Tree and Logistic Regression have nearly perfect recall (1.0), meaning they detect more positive result.

Decision Tree has more overfitting because the train acc 1.0 and test acc 0.7064.

Logistic Regression and Boost have a balanced performance but lower recall.

Generally, Random Forest is the best in this scenario with best balance of metrics especially high test accuracy and F1.


For Balanced Data:
Random Forest has the best test accuracy (0.7768) and highest F1 score (0.874).

Decision Tree has perfect train accuracy but low test accuracy.

Logistic Regression test accuracy drops significantly to 0.636.

Gradient Boost and SVM have lower test accuracies and F1 scores.

In conclusion,

Decision Tree shows overfitting in both cases.

Logistic Regression has lower test accuracy on balanced data.

Gradient Boost and SVM did not perform well on balanced targets in test accuracy and F1.

Random Forest consistently has balanced performance in this scena
rio

Hence Random Forest will be considered the best model in this scenario based on these metrics for both unbalanced and balanced datasets.

#### EDA
"""



#visualization
for col in num_cols_base:
    plt.subplot(1,2,1)
    #plt.figure(figsize=(10,4))  #to make the plot wider
    sns.histplot(x[col], kde=True, bins=10)
    plt.title(f'{col}')
    plt.ylabel('count')
    plt.xlabel(col)
    plt.show()


for col in num_cols_base:
    plt.subplot(1,2,2)  # to space the different hist plots
    sns.boxplot(x=x[col], color='red')    #x changes the orientation of the boxplot
    plt.title(f'{col} boxplot')
    plt.xlabel(col)

    plt.tight_layout()
    plt.show()

#categorical columns
for col in cat_cols_base:
    plt.figure(figsize=(6,4))
    sns.countplot(x[col], color='green')
    plt.title(f'{col} distribution')
    plt.xlabel(col)
    plt.ylabel('count')

    plt.show()

#categorical columns 2 optional
fig, axes = plt.subplots(2,2,figsize=(5,4))
for i, col in enumerate(cat_cols_base):
    ax= axes[1//2, 1%2]
    sns.countplot(ax = ax, data=x, x= col)
    ax.set_title(f' {col}')
plt.tight_layout()

plt.show()

#to check skewness

skewness= x[num_cols_base].skew().sort_values(ascending=False)

skewness

"""#### The skewness in latitude_gps column is greater than 1 and longitude_gps is skewed to the left by 3, hence it is an extreme skewness hence it shall be treated(transformed) using logarithm transformation"""

#to deal with outliers

for col in['latitude_gps','longitude_gps','term_days','loan_number']:
#logarithm + winsorisation
    upper = x[col].quantile(0.95)
    x[f'{col}_log'] = np.log(x[col].clip(upper=upper)) #add 1p to the log if there are zeros in the column dataset
    x[f'{col}_sqrt'] = np.log(x[col].clip(upper=upper))

    import warnings
    warnings.filterwarnings('ignore')

x.columns

#to check skewness

skewness= x[num_cols_base].skew().sort_values(ascending=False)

skewness

#detecting outliers using inter-quantile range

def detect_outliers(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5*IQR
    upper_bound = Q3 + 1.5*IQR
    return[ (series<lower_bound) | (series>upper_bound)]

#outliers from the num cols

for col in num_cols_base:
    outliers= len(detect_outliers(x[col]))
    print(outliers)

x_treat = x.drop(columns=['longitude_gps','latitude_gps','latitude_gps_sqrt', 'longitude_gps_sqrt','loan_number_sqrt','term_days_sqrt',])

x_treat.info()

values_array =pd.DataFrame(temp_df['system_loan_id'])
print(values_array.head().sort_values(by='system_loan_id'))

x_treat.isna().sum()

#fill the missing values of the column that has less than 20 percent missing values


mode = x_treat['longitude_gps_log'].mode()[0]  #finds the mode value of the column

x_treat['longitude_gps_log'] = x_treat['longitude_gps_log'].fillna(mode) #fill in the missing values with mode value


mode = x_treat['latitude_gps_log'].mode()[0]

x_treat['latitude_gps_log'] = x_treat['latitude_gps_log'].fillna(mode)

x_treat.isna().sum()

num_cols= x_treat.select_dtypes(include=np.number).columns.tolist()# separate into cat_cols and num_cols
cat_cols = x_treat.select_dtypes(include='object').columns.tolist()

#to check skewness

skewness= x_treat[num_cols].skew().sort_values(ascending=False)

skewness

#visualization
for col in num_cols:
    plt.subplot(1,2,1)
    #plt.figure(figsize=(10,4))  #to make the plot wider
    sns.histplot(x_treat[col], kde=True, bins=10)
    plt.title(f'{col}')
    plt.ylabel('count')
    plt.xlabel(col)
    plt.show()


for col in num_cols:
    plt.subplot(1,2,2)  # to space the different hist plots
    sns.boxplot(x=x_treat[col], color='red')    #x changes the orientation of the boxplot
    plt.title(f'{col} boxplot')
    plt.xlabel(col)

    plt.tight_layout()
    plt.show()

y.unique()

#split into train and test
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x_treat,y, test_size=0.2, random_state=42, stratify=y)

#we have to covert target column to numbers by using label encoder
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
# Here we fit the encoder on the training  and then transform
y_encode_train = label_encoder.fit_transform(y_train)
y_encode_test = label_encoder.transform(y_test)

#To create a pipeline for the data preprocessing

num_pipeline = Pipeline(steps=[
    ('scalar', StandardScaler())
    ])
cat_pipeline = Pipeline(steps=[
    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))
    ])

#Applying the preprocessing

preprocessor = ColumnTransformer(transformers= [
    ('num', num_pipeline, num_cols),
    ('cat', cat_pipeline, cat_cols)
])

#we pass the preprocessor to the training data.
x_train_processed = preprocessor.fit_transform(x_train)
x_test_processed = preprocessor.transform(x_test)

# we can now apply SMOTE to the processed training data.

from imblearn.over_sampling import SMOTE

smote_base = SMOTE(random_state=42)

x_train_bal, y_train_bal = smote_base.fit_resample(x_train_processed, y_encode_train)

#We visualize the balanced target column

import seaborn as sns

sns.countplot(x=y_train_bal)

# Commented out IPython magic to ensure Python compatibility.
#Fit and evaluate the models
results3 = {}

fig, axes = plt.subplots(2,3, figsize=(15, 8))


for (name, model), ax in zip (models.items(), axes. flatten()):

    pipeline= Pipeline(steps=[
        #('preprocessor', preprocessor),
        ('model', model)
    ])
    #model training
#     %time
    pipeline.fit(x_train_bal, y_train_bal)
     #prediction
    train_pred = pipeline.predict(x_train_processed)
    test_pred = pipeline.predict(x_test_processed)
#train_base_pred,test_base_pred

#Evaluation

    train_score_base = accuracy_score(y_encode_train, train_pred)
    test_score_base = accuracy_score(y_encode_test, test_pred)
    precision = precision_score(y_encode_test, test_pred)
    recall = recall_score(y_encode_test, test_pred)
    f1 = f1_score(y_encode_test, test_pred)

    results3[name] = {
    "Train Accuracy": train_score_base,
    "Test Accuracy": test_score_base,
    "Precision Score": precision,
    "Recall Score": recall,
    "F1 Score": f1
    }

    cm= confusion_matrix(y_encode_train, train_pred)
    disp = ConfusionMatrixDisplay(cm, display_labels=['No','Yes'])
    disp.plot(ax=ax, cmap = 'Blues')
    ax.set_title(name)

plt.tight_layout()
plt.show()


#print matrics
print('\nclassification Metrics')
metrics_df=pd.DataFrame(results3)
print(metrics_df.round(2))

pd.DataFrame(results3)

"""#### OBSERVATIONS AFTER TRANSFORMING(EDA) THE FEATURE COLUMNNS

##### Models involved
Logistic Regression

Decision Tree

Random Forest

Gradient Boost

Support Vector Machine (SVM)

###### Training Accuracy
Training accuracy remained high close to or equal 1 for Logistic Regression, Decision Tree, and Random Forest in both the untransformed and transformed features maybe due to overfitting.

While, Boost and SVM have a relatively lower training accuracy. And Boost reduced from 0.78 (untransformed) to 0.69 (transformed) maybe because of the transformation affecting the model.

###### Test Accuracy
The Test accuracy is also a bit stable for all the models:

-Logistic Regression moved from 0.749 to 0.755

-Decision Tree moved from 0.701 to 0.735

-SVM moved from 0.338 to 0.364

-Random Forest remained consistent at 0.781 before and after features transformation.

-Gradient Boost reduced from 0.657 to 0.619 that means the features transformation affected it's performance badly.

###### Precision Score
Precision scores also remained relatively consistent for the models, but SVM and Boost improved after transformation from 0.795 to 0.814 and from 0.799 to 0.801 respectively.

###### Recall Score
The Recall score improved a little for Logistic Regression and Decision Tree after features transformation.

Random Forest maintains perfect recall score of 1.0 for untransformed and the transformed features.

Boost has reduced recall score from 0.749 to 0.681.

SVM recall score improve but it is still low from 0.205 to 0.241 which means it is not too sensitive.

###### F1 Score
-Logistic Regression has a slight increase F1 score from 0.854 to 0.858 and Decision Tree from 0.813 to 0.840.

-Random Forest remains the highest F1 score 0.877 and did not change after feature transformation.

-Boostâ€™s F1 score reduced a little from 0.774 to 0.737 just as it reduced in the train and test accuracy.

-SVM improved a little but remains low from 0.326 to 0.371.

##### Conclusions and Recommendations
Random Forest has the relatively highest and consistent performance for both untransformed and transformed features. It has high recall score, precision score and F1 score. This model is the most preferred for this scenario and worthy of further tuning and possibly for deployment.

Logistic Regression and Decision Tree slightly improved after feature transformation in test accuracy, recall score and F1 score. Both can also be considered for further tuning in this scenario after Random Forest.

Gradient Boost model performance decreases slightly after the feature transformation and may not be considered for this scenario.

SVM model has the least performance even after feature transformation and balancing the target column.Hence it is the least preferred in this scenario.

Generally, the balancing of the target column and the features transformation tends to improve the models' generalization and performance in this scenario.

##### FEATURE IMPORTANCE
"""

#USING THE BEST MODEL FOR THIS SCENARIO

final_model = RandomForestClassifier(random_state=42)

# Commented out IPython magic to ensure Python compatibility.
#Fit and evaluate the models
results_final = {}

fig, ax = plt.subplots(1,1, figsize=(15, 8))

pipeline= Pipeline(steps=[

#('preprocessor', preprocessor),
('model', final_model)])
    #model training
# %time
pipeline.fit(x_train_bal, y_train_bal)

  #prediction
train_pred = pipeline.predict(x_train_processed)
test_pred = pipeline.predict(x_test_processed)


    #Evaluation
train_score_base = accuracy_score(y_encode_train, train_pred)
test_score_base = accuracy_score(y_encode_test, test_pred)
precision = precision_score(y_encode_test, test_pred)
recall = recall_score(y_encode_test, test_pred)
f1 = f1_score(y_encode_test, test_pred)

results_final[name] = {
    "Train Accuracy": train_score_base,
    "Test Accuracy": test_score_base,
    "Precision Score": precision,
    "Recall Score": recall,
    "F1 Score": f1
    }

cm= confusion_matrix(y_encode_train, train_pred)
disp = ConfusionMatrixDisplay(cm, display_labels=['No','Yes'])
disp.plot(ax=ax, cmap = 'Blues')
ax.set_title(name)

plt.tight_layout()
plt.show()

#print matrics
print('\nclassification Metrics')
metrics_final=pd.DataFrame(results_final)
print(metrics_final.round(2))

pd.DataFrame(results_final)

x_train_final = preprocessor.transform(x_train)
final_model.fit(x_train_final, y_train)

feature_names = (num_cols + list(preprocessor.named_transformers_['cat'].named_steps['encoder'].get_feature_names_out(cat_cols)))



importance = final_model.feature_importances_

importance

sort = np.argsort(importance)[::-1]

sort

feature_names_arr = np.array(feature_names)

plt.figure(figsize=(10,10))
plt.bar(range(len(importance)), importance[sort])
plt.xticks(range(len(importance)), np.array(feature_names_arr[sort]), rotation=90)
plt.show()

print(len(importance), len(sort), len(feature_names_arr))

#import numpy as np
#import matplotlib.pyplot as plt

# Number of top features to plot
top_n = 15

# Sort indices of importance in descending order
sorted_indices = np.argsort(importance)[::-1][:top_n]

# Select top feature names and their importances
top_feature_names = feature_names_arr[sorted_indices]
top_importances = importance[sorted_indices]

# Plot
plt.figure(figsize=(12, 6))
plt.bar(range(top_n), top_importances, color='skyblue')
plt.xticks(range(top_n), top_feature_names, rotation=90)
plt.xlabel('Feature Names')
plt.ylabel('Importance')
plt.title(f'Top {top_n} Feature Importances')
plt.tight_layout()
plt.show()

#SAVE AND TEST MODEL

import joblib

final_pipeline = Pipeline(steps=[
                    ('preprocessor', preprocessor),
                    ('model', RandomForestClassifier(random_state=42))

])

# Commented out IPython magic to ensure Python compatibility.
# %time
final_pipeline.fit(x,y)

import pandas as pd

data = {
    'loan_number':[5],
    'loan_amount':[15000.0],
    'total_due':[17250.0],
    'term_days':[30],
    'birth_date':['1990-01-01 00:00:00.000000'],
    'bank_account_type':['Savings'],
    'longitude_gps':[3.325598],
    'latitude_gps':[7.119403],
    'bank_name_clients':['GT Bank'],
    'employment_status_clients':['Permanent']
}

"""#### DEPLOYMENT"""

#To save the model

joblib.dump(final_pipeline, "loan_predictor.pkl")

model = joblib.load('loan_predictor.pkl')

#create a dataframe
df=pd.DataFrame(data)

df

# To deal with outliers using logarithm + winsorisation for the new data
for col in['latitude_gps','longitude_gps','term_days','loan_number']:
    upper = df[col].quantile(0.95)
    # Add 1e-9 to handle zero values before applying log transformation
    df[f'{col}_log'] = np.log1p(df[col].clip(upper=upper) + 1e-9)
#df = pd.DataFrame(data)


# Now predict using the model with the transformed features
loan_flag = model.predict(df)

print(loan_flag)

df